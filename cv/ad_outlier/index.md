# 4章 近傍法による異常検知
- ホテリングが有効なのは観測値が1点に集中してる時だけ
- その縛りもなく簡単なのが近傍法
- 距離の決め方が大事
- 「距離のリーマン計量」を最適化して近傍法をいい感じに
- 「マージン最大化近傍法」を紹介

## 4.1 k近傍法: 経験分布に基づく異常判定

## 4.1 要約
- 4.1.1
  - 「経験分布」を使って異常検知する
  - 近くにある点の数が規定数入る円の半径ε
  - デルタ関数なので経験した時だけ1になり他は0になる
  - 半径εが同じなら要素数kが少ないと異常度が高い
  - 要素数kが同じ数なら，半径εが大きい方が異常度が高い
  - 「k近傍法」は要素数kを固定して異常判定する方法
  - 「ε近傍法」は半径εを固定して異常判定する
  - 分布がいくつかの集団に分かれていてOKなのがホテリングよりもいい点
  - 塊具合の違いや次元数が増えて寄与度が減るといった弱点もある

- 4.1.2 「ラベルつきデータに対するk近傍法」
  - ラベルがある場合は，異常と正常で分けて分布を作る
  - 観測点x'について，正常である確率は近傍のkこのうち正常ラベルの点の割合になる
  - ベイズの定理から，異常度a(x')は正常と異常の対数比で表される
  - これを使うには，「近傍数k」と「異常判定の閾値a_th」を「1つ抜き交差確認法」を使って決める
  - 近傍法では「距離尺度」を決める必要がある
  - フツーはユークリッド距離を使う
  - 距離や異常度の計算方法を決めるには，「局所外れ値度」という手法が良い

## 4.2 要約